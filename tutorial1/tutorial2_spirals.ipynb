{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWxxmBLYKoln"
      },
      "source": [
        "# Tutorial 2: Feedforward neural networks in PyTorch\n",
        "\n",
        "PSI 2022-2023\n",
        "\n",
        "Machine Learning for Many-Body Physics\n",
        "\n",
        "March 7, 2023\n",
        "\n",
        "Code by Lauren Hayward, Juan Carrasquilla, and Mohamed Hibat Allah"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuUm4oZtGM77"
      },
      "source": [
        "## Create and plot the data set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD4zSMIhdITs"
      },
      "source": [
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "N = 50 # number of points per branch\n",
        "K = 3  # number of branches\n",
        "\n",
        "N_train = N*K # total number of points in the training set\n",
        "x_train = np.zeros((N_train,2)) # matrix containing the 2-dimensional datapoints\n",
        "y_train = np.zeros(N_train, dtype='uint8') # labels (not in one-hot representation)\n",
        "\n",
        "mag_noise = 0.3  # controls how much noise gets added to the data\n",
        "dTheta    = 4    # difference in theta in each branch\n",
        "\n",
        "### Data generation: ###\n",
        "for j in range(K):\n",
        "  ix = range(N*j,N*(j+1))\n",
        "  r  = np.linspace(0.01,1,N) # radius\n",
        "  th = np.linspace(j*(2*np.pi)/K,j*(2*np.pi)/K + dTheta,N) + np.random.randn(N)*mag_noise # theta\n",
        "  x_train[ix] = np.c_[r*np.cos(th), r*np.sin(th)]\n",
        "  y_train[ix] = j\n",
        "\n",
        "### Plot the data set: ###\n",
        "fig = plt.figure(1, figsize=(5,5))\n",
        "plt.scatter(x_train[:, 0], x_train[:, 1], c=y_train, s=40)#, cmap=plt.cm.Spectral)\n",
        "plt.xlim([-1,1])\n",
        "plt.ylim([-1,1])\n",
        "plt.xlabel(r'$x_1$')\n",
        "plt.ylabel(r'$x_2$')\n",
        "plt.savefig('spiral_data.pdf', bbox_inches=\"tight\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmyO880M8mRO"
      },
      "source": [
        "#Run this cell if you want to save a pdf plot of the dataset:\n",
        "#files.download('spiral_data.pdf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnVlZ9Gf96KC"
      },
      "source": [
        "## Define the network architecture and training hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG5DlljlSEvB"
      },
      "source": [
        "%matplotlib inline\n",
        "from IPython import display\n",
        "\n",
        "import time\n",
        "import torch\n",
        "\n",
        "class FeedforwardNN(torch.nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(FeedforwardNN, self).__init__()\n",
        "\n",
        "        #layer sizes:\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        #functions used within the Feedforward NN:\n",
        "        self.linear1 = torch.nn.Linear(self.input_size, self.output_size)\n",
        "        self.relu    = torch.nn.ReLU()\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "        self.softmax = torch.nn.Softmax()\n",
        "    def forward(self, x):\n",
        "        #Layer 1:\n",
        "        linear1_out = self.linear1(x)\n",
        "        a1 = self.sigmoid(linear1_out)\n",
        "\n",
        "        #Network output:\n",
        "        aL = a1\n",
        "\n",
        "        return aL\n",
        "\n",
        "input_size = 2\n",
        "output_size = K\n",
        "model = FeedforwardNN(input_size, output_size)\n",
        "\n",
        "### Store the input data as a PyTorch tensor ###\n",
        "x_train = torch.tensor(x_train, dtype = torch.float)\n",
        "\n",
        "### One hot encoding ###\n",
        "y_onehot = np.zeros((y_train.size, K))\n",
        "y_onehot[np.arange(y_train.size),y_train] = 1\n",
        "y_onehot = torch.tensor(y_onehot, dtype = torch.float)\n",
        "\n",
        "### Use backpropagation to minimize the cost function using the gradient descent algorithm: ###\n",
        "learning_rate = 1\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "### Cost function: ###\n",
        "cost_func = torch.nn.MSELoss()\n",
        "\n",
        "N_epochs = 10000 # number of times to run gradient descent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOtexsTq-EfC"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ng0FlPl-YNf"
      },
      "source": [
        "epoch_list    = []\n",
        "cost_training = []\n",
        "acc_training  = []\n",
        "\n",
        "############ Function for plotting: ############\n",
        "def updatePlot():\n",
        "\n",
        "    ### Generate coordinates covering the whole plane: ###\n",
        "    padding = 0.1\n",
        "    spacing = 0.02\n",
        "    x1_min, x1_max = x_train[:, 0].min() - padding, x_train[:, 0].max() + padding\n",
        "    x2_min, x2_max = x_train[:, 1].min() - padding, x_train[:, 1].max() + padding\n",
        "    x1_grid, x2_grid = np.meshgrid(np.arange(x1_min, x1_max, spacing),\n",
        "                         np.arange(x2_min, x2_max, spacing))\n",
        "\n",
        "    torch_input = torch.tensor(np.c_[x1_grid.ravel(), x2_grid.ravel()], dtype = torch.float)\n",
        "    NN_output = model(torch_input)\n",
        "    predicted_class = np.argmax(NN_output.detach().numpy(), axis=1)\n",
        "\n",
        "    ### Plot the classifier: ###\n",
        "    plt.subplot(121)\n",
        "    plt.contourf(x1_grid, x2_grid, predicted_class.reshape(x1_grid.shape), K, alpha=0.8)\n",
        "    plt.scatter(x_train[:, 0], x_train[:, 1], c=y_train, s=40)\n",
        "    plt.xlim(x1_grid.min(), x1_grid.max())\n",
        "    plt.ylim(x2_grid.min(), x2_grid.max())\n",
        "    plt.xlabel(r'$x_1$')\n",
        "    plt.ylabel(r'$x_2$')\n",
        "\n",
        "    ### Plot the cost function during training: ###\n",
        "    plt.subplot(222)\n",
        "    plt.plot(epoch_list,cost_training,'o-')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Training cost')\n",
        "\n",
        "    ### Plot the training accuracy: ###\n",
        "    plt.subplot(224)\n",
        "    plt.plot(epoch_list,acc_training,'o-')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Training accuracy')\n",
        "############ End of plotting function ############\n",
        "\n",
        "### Train for several epochs: ###\n",
        "for epoch in range(N_epochs):\n",
        "\n",
        "    optimizer.zero_grad() # sets the gradients to zero (necessary since PyTorch accumulates the gradients)\n",
        "    NN_output = model(x_train) # Neural network output\n",
        "    cost = cost_func(NN_output, y_onehot)\n",
        "    cost.backward() #computes the gradients\n",
        "    optimizer.step() #updating the parameters\n",
        "\n",
        "    ### Update the plot and print results every 500 epochs: ###\n",
        "    if epoch % 500 == 0:\n",
        "        predicted_class = np.argmax(NN_output.detach().numpy(), axis=1)\n",
        "        accuracy = np.mean(predicted_class == y_train)\n",
        "\n",
        "        epoch_list.append(epoch)\n",
        "        cost_training.append(cost.detach().numpy())\n",
        "        acc_training.append(accuracy)\n",
        "\n",
        "        ### Update the plot of the resulting classifier: ###\n",
        "        fig = plt.figure(2,figsize=(10,5))\n",
        "        fig.subplots_adjust(hspace=.3,wspace=.3)\n",
        "        plt.clf()\n",
        "        updatePlot()\n",
        "        display.display(plt.gcf())\n",
        "        print(\"Iteration %d:\\n  Training cost %f\\n  Training accuracy %f\\n\" % (epoch, cost, accuracy) )\n",
        "        display.clear_output(wait=True)\n",
        "        # time.sleep(0.1) #Uncomment this line if you want to slow down the rate of plot updates\n",
        "\n",
        "plt.savefig('spiral_results.pdf', bbox_inches=\"tight\")\n",
        "print(\"Final Training cost %f\\nFinal Training accuracy %f\\n\" % (cost, accuracy) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CwmTP3jHIUA"
      },
      "source": [
        "#Run this cell if you want to save a pdf plot of the results:\n",
        "#files.download('spiral_results.pdf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8QrYKVf-0vni"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
